{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# For visualization\n",
    "import plotly as pl\n",
    "import hvplot.pandas\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing ahead of running ML Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import sklearn as skl \n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, \n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroid\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "#For ML models\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, classification_report  \n",
    "from imblearn.metrics import classification_report_imbalanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = Path('C:/Users/esobieski/Documents/Berkeley/TeamPySpark/loans.csv')\n",
    "loans_df = pd.read_csv(file_path)  \n",
    "loans_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: Exploration steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all column names\n",
    "loans_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Counts to Explore Columns for keeping/removal of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to keep DISTRIBUTION MODEL\n",
    "clean_loans_df.DISTRIBUTION_MODEL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to keep REPAYMENT INTERVAL\n",
    "clean_loans_df.REPAYMENT_INTERVAL.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to keep REPAYMENT INTERVAL\n",
    "clean_loans_df.STATUS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to keep ORIGINAL LANGUAGE\n",
    "clean_loans_df.ORIGINAL_LANGUAGE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to REMOVE   NUMBER OF BULK ENTRIES - assume not useful\n",
    "clean_loans_df.NUM_BULK_ENTRIES.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to remove CURRENCY , keep COUNTRY instead\n",
    "clean_loans_df.CURRENCY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK to remove LOAN USE - too specific, not good for ML model, will do NLP on tags instead\n",
    "clean_loans_df.LOAN_USE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate time elapsed and clean up time elapsed outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variables to find time elapsed from when request was posted to when it was funded.\n",
    "raised_time = pd.to_datetime(loans_df[\"RAISED_TIME\"])\n",
    "posted_time = pd.to_datetime(loans_df[\"POSTED_TIME\"])\n",
    "elapsed_time_df = raised_time - posted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of elapsed time amounts\n",
    "elapsed_time_df.astype(\"timedelta64[D]\").hist(range=[-5, 25])\n",
    "# 12 days is our cutoff for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats for elapsed time\n",
    "elapsed_time_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 203 times where elapsed time is negative - REMOVE THEM BELOW\n",
    "sum(elapsed_time_df < pd.to_timedelta(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display df\n",
    "elapsed_time_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete negative elapsed time\n",
    "clean_elapsed_time_df = elapsed_time_df[elapsed_time_df > pd.to_timedelta(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove bad data from original dataframe using the same index, that way clean elapsed_time_df will have same number of rows\n",
    "# to be merged back into dataframe\n",
    "clean_loans_df = loans_df[elapsed_time_df > pd.to_timedelta(0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform gender column into Male and Female columns with numbers not words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that column is still in string\n",
    "loans_df[\"BORROWER_GENDERS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a function for converting strings to number objects\n",
    "# But then group of all males and one female comes up as 1, looks like 1 single female\n",
    "# KEEP IN MIND WHEN INTERPRETING RESULTS\n",
    "\n",
    "clean_loans_df.BORROWER_GENDERS.astype(str)\n",
    "\n",
    "test_string = \"male, female, male\"\n",
    "\n",
    "def female(txt):\n",
    "    lst = txt.split(\", \")\n",
    "    count = 0\n",
    "    for x in lst:\n",
    "        if x == \"female\":\n",
    "            count +=1 \n",
    "    return count\n",
    "\n",
    "def male(txt):\n",
    "    lst = txt.split(\", \")\n",
    "    count = 0\n",
    "    for x in lst:\n",
    "        if x == \"male\":\n",
    "            count +=1 \n",
    "    return count\n",
    "\n",
    "female(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a working copy of the loans_df dataframe\n",
    "working_loans_df = clean_loans_df.copy()\n",
    "working_loans_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datatypes for gender to string\n",
    "working_loans_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the gender column in working_loans_df\n",
    "working_loans_df = clean_loans_df['BORROWER_GENDERS'].dropna()\n",
    "working_loans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the male and female gender functions to the dataset, yields a number value for each field. \n",
    "male_df = working_loans_df.apply(male)\n",
    "female_df = working_loans_df.apply(female)\n",
    "male_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of gender columns male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distrubtion histogram of females\n",
    "female_df.hist(range=[-2, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distribution histogram of males \n",
    "male_df.hist(range=[-2, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value for number of males (1.3 million borrowers have no men in the group or solo business)\n",
    "clean_loans_df['MALE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value for number of females (362 thousand borrowers have no women in the group or solo business)\n",
    "clean_loans_df['FEMALE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Male, Female, and Elapsed Time dataframes back into clean_loans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge male into clean_loans_df \n",
    "clean_loans_df[\"MALE\"]=male_df\n",
    "# Check dataframe\n",
    "clean_loans_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Female column back into DF\n",
    "clean_loans_df[\"FEMALE\"]=female_df\n",
    "# Check dataframe\n",
    "clean_loans_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Elapsed Time back into df\n",
    "clean_loans_df[\"FUNDING_TIME\"]= clean_elapsed_time_df\n",
    "# Check dataframe\n",
    "clean_loans_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing unnecessary and repetitive columns from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing refunded and expired out of status.  This removes all rows that are not \"funded\" from the dataset.\n",
    "# Thus we are only looking at the speed at which loans are funded.\n",
    "clean_loans_df = clean_loans_df.loc[clean_loans_df[\"STATUS\"]==\"funded\"]\n",
    "clean_loans_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all obviously unneeded columns \n",
    "clean_loans_df.drop(['LOAN_ID', 'LOAN_NAME', 'LOAN_AMOUNT', 'STATUS','DESCRIPTION','DESCRIPTION_TRANSLATED','IMAGE_ID', 'VIDEO_ID', 'LOAN_USE','COUNTRY_CODE', 'TOWN_NAME', 'CURRENCY_POLICY',\n",
    "       'CURRENCY_EXCHANGE_COVERAGE_RATE', 'CURRENCY', 'POSTED_TIME', 'PLANNED_EXPIRATION_TIME', 'DISBURSE_TIME','RAISED_TIME', 'LENDER_TERM', 'NUM_JOURNAL_ENTRIES', 'NUM_BULK_ENTRIES', 'BORROWER_NAMES','BORROWER_GENDERS','BORROWER_PICTURED'], axis=1, inplace=True)\n",
    "clean_loans_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a manual binary classification of time into model DF, SUCCESS is when speed of borrowing is under 12 days, 12 days or more is not successful in terms of the speed - how fast does the loan fund?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of clean_loans_df\n",
    "bc_model_df = clean_loans_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE FOR BINARY CLASSIFICATION\n",
    "# Preprocess FUNDING_TIME such that mean = 12 days is cutoff for successful loan funding.  \n",
    "Under_12days = bc_model_df[\"FUNDING_TIME\"] < pd.to_timedelta(\"12 days\")\n",
    "bc_model_df[\"SUCCESS\"] = Under_12days.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE FUNDING TIME from model_df\n",
    "bc_model_df.drop(['FUNDING_TIME'], axis=1, inplace=True)\n",
    "bc_model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating mc_reg_df for multiple classification (MC) models (time buckets where measure of success is speed of borrowing).  bc_model_df will be for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of clean_loans_df\n",
    "mc_reg_df = clean_loans_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bucket with time delta intervals\n",
    "\n",
    "bins = [\n",
    "    pd.Timedelta(weeks = 0),\n",
    "    pd.Timedelta(weeks = 1),\n",
    "    pd.Timedelta(weeks = 2),\n",
    "    pd.Timedelta(weeks = 3),\n",
    "    pd.Timedelta(weeks = 4),\n",
    "    pd.Timedelta(weeks = 5)\n",
    "]\n",
    "labels = [1,2,3,4,5,6]\n",
    "mc_reg_df[\"FUNDING_WEEKS\"] = pd.cut(mc_reg_df[\"FUNDING_TIME\"], bins, labels=labels)\n",
    "mc_reg_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE FUNDING_TIME column from mc_reg_df\n",
    "mc_reg_df.drop(['FUNDING_TIME'], axis=1, inplace=True)\n",
    "mc_reg_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing separate Dataframe for Binary Classification NLP on CoLab via exported CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of clean_loans_df for export to NLP projec\n",
    "tags_df = bc_model_df.copy()\n",
    "tags_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NLP column names\n",
    "tags_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns except TAGS\n",
    "tags_df.drop(['ORIGINAL_LANGUAGE', 'FUNDED_AMOUNT', 'ACTIVITY_NAME','SECTOR_NAME', 'COUNTRY_NAME', 'PARTNER_ID', 'NUM_LENDERS_TOTAL','REPAYMENT_INTERVAL', 'DISTRIBUTION_MODEL', 'MALE', 'FEMALE', 'SUCCESS'], axis=1, inplace=True)\n",
    "tags_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in bc_df\n",
    "tags_df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "tags_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "tags_df.to_csv(\"tags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing separate Dataframe for Binary Classification NLP on CoLab via exported CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of clean_loans_df for export to NLP projec\n",
    "bc_nlp_df = bc_model_df.copy()\n",
    "bc_nlp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NLP column names\n",
    "bc_nlp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_nlp_df.drop(['ORIGINAL_LANGUAGE', 'FUNDED_AMOUNT', 'ACTIVITY_NAME','SECTOR_NAME', 'COUNTRY_NAME', 'PARTNER_ID', 'NUM_LENDERS_TOTAL','REPAYMENT_INTERVAL', 'DISTRIBUTION_MODEL', 'MALE', 'FEMALE'], axis=1, inplace=True)\n",
    "bc_nlp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "bc_nlp_df.to_csv(\"bc_nlp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing separate Dataframe for Multiple Classification NLP on CoLab via exported CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of mc_reg_df for export to NLP project\n",
    "mc_nlp_df = mc_reg_df.copy()\n",
    "mc_nlp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NLP column names\n",
    "mc_nlp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_nlp_df.drop(['ORIGINAL_LANGUAGE', 'FUNDED_AMOUNT', 'ACTIVITY_NAME','SECTOR_NAME', 'COUNTRY_NAME', 'PARTNER_ID', 'NUM_LENDERS_TOTAL','REPAYMENT_INTERVAL', 'DISTRIBUTION_MODEL', 'MALE', 'FEMALE'], axis=1, inplace=True)\n",
    "mc_nlp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "mc_nlp_df.to_csv(\"mc_nlp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_nlp_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Tags after creating both NLP CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping TAGS column from BINARY classification\n",
    "bc_model_df.drop(['TAGS'], axis=1, inplace=True)\n",
    "bc_model_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping TAGS column from MULTIPLE classification\n",
    "mc_reg_df.drop(['TAGS'], axis=1, inplace=True)\n",
    "mc_reg_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLING TECHNIQUES: should all 3 or last 2 be after train/test split???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare both BC and MC dataframes for ML through sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a sample of the data as using all did not work for get dummies (3% used) - not as much needed as only BC\n",
    "bc_df = bc_model_df.sample(frac =.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a sample of the data as using all did not work for get dummies (6% used)\n",
    "mc_df = mc_reg_df.sample(frac =.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove null values from sampled BC and MC dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many NaNs are in bc_df\n",
    "bc_df.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many NaNs are in mc_df\n",
    "mc_df.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in bc_df\n",
    "bc_df.dropna(axis=0, how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values in mc_df\n",
    "mc_df.dropna(axis=0, how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final bc_df\n",
    "bc_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final mc_df\n",
    "mc_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for machine learning models that will use binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression, our binary classification is that a successful borrowing event results in full funding within 12 days.  An unsucessful event would be funding taking longer than 12 days, as a reflection of less lender enthusiasm to fund the loan.  This removes the issue in the data that 99%+ of loans get funded and thus the data is very unbalanced if you just look at funding vs didn't fund.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features  NOT SURE ABOUT THIS VS THE TRAINING AND TESTING A FEW CELLS DOWN\n",
    "\n",
    "X = bc_df.copy()\n",
    "X = X.drop('SUCCESS', axis=1)\n",
    "\n",
    "# Create our target\n",
    "y = bc_df[['SUCCESS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe X  -- MOST BORROWERS ARE SOLO FEMALES\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values  \n",
    "# Used a calculated value of TIME TO FULL FUNDING using date stamps in prep for LOGISTIC REGRESSION\n",
    "# SUCCESS is funding in 12 days or less\n",
    "\n",
    "y['SUCCESS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels (DO WE USE THIS OR ONE HOT ENCODER?)\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TRAIN-TEST SPLIT AFTER GETTING DUMMIES AND BEFORE SCALING, SO RIGHT HERE\n",
    "# Dataset is split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "    y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALING X_TRAIN STEP \n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "print(X_train_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALING X_TEST STEP HERE \n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "print(X_test_scaled[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and scale data for machine learning models that will use multiple classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear regression, Random Forest and Neural nets, we use buckets of time, 1, 2, 3, 4, and 5 weeks, so that it can both classify and be continuous.  This is our mc_df.  We notate all these with mc in front so we can run either pre-prepared through multiple models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features  NOT SURE ABOUT THIS VS THE TRAINING AND TESTING A FEW CELLS DOWN\n",
    "\n",
    "mcX = mc_df.copy()\n",
    "mcX = mcX.drop('FUNDING_WEEKS', axis=1)\n",
    "\n",
    "# Create our target\n",
    "mcy = mc_df[['FUNDING_WEEKS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe X  -- MOST BORROWERS ARE SOLO FEMALES\n",
    "\n",
    "mcX.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out y\n",
    "\n",
    "mcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values  \n",
    "# Used a calculated value of TIME TO FULL FUNDING using date stamps in prep for LOGISTIC REGRESSION\n",
    "# SUCCESS is funding in 12 days or less\n",
    "\n",
    "mcy['FUNDING_WEEKS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels (DO WE USE THIS OR ONE HOT ENCODER?)\n",
    "\n",
    "mcX = pd.get_dummies(mcX)\n",
    "mcX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TRAIN-TEST SPLIT AFTER GETTING DUMMIES AND BEFORE SCALING\n",
    "# Dataset is split into training and testing sets\n",
    "mcX_train, mcX_test, mcy_train, mcy_test = train_test_split(mcX,\n",
    "    mcy, random_state=1, stratify=mcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALING X_TRAIN STEP \n",
    "mcX_train_scaled = StandardScaler().fit_transform(mcX_train)\n",
    "print(mcX_train_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALING X_TEST STEP HERE \n",
    "mcX_test_scaled = StandardScaler().fit_transform(mcX_test)\n",
    "print(mcX_test_scaled[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling: because \"y\" is very right skewed leading to 50% of the data in one of 6 one-week buckets, thus model performance is 50%.  When it is 2 buckets, set at the mean of 12 days, then model performance is 69%, equal to the amount of \"y\" data in the 1 position, so again model is not effective, same prediction as the distribution of \"y\" data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Oversampling on binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check imbalance in y\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random oversampling to rebalance y ???? SHOULD I DO THIS FOR X AND Y or just Y?\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on how much Y was rebalanced for Random oversampling\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Minority Undersamping on binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Minority Oversampling\n",
    "X_resampled, y_resampled = SMOTE(random_state=1,\n",
    "sampling_strategy='auto').fit_resample(\n",
    "   X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See results of Synthetic Minority Undersampling\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Oversampling on binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomUnderSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See results of Synthetic Minority Undersampling\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Undersampling on binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Centroid Undersampling on binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling: combination oversampling and undersampling with SMOTEEN on binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Oversampling on multiple classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check imbalance in y\n",
    "Counter(mcy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random oversampling to rebalance y ???? SHOULD I DO THIS FOR X AND Y or just Y?\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "mcX_resampled, mcy_resampled = ros.fit_resample(mcX_train, mcy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on how much Y was rebalanced for Random oversampling\n",
    "Counter(mcy_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Minority Undersamping on multiple classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Minority Oversampling\n",
    "mcX_resampled, mcy_resampled = SMOTE(random_state=1,\n",
    "sampling_strategy='auto').fit_resample(\n",
    "   mcX_train, mcy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See results of Synthetic Minority Undersampling\n",
    "Counter(mcy_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Undersampling on multiple classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Undersampling on multiple classification model\n",
    "ros = RandomUnderSampler(random_state=1)\n",
    "mcX_resampled, mcy_resampled = ros.fit_resample(mcX_train, mcy_train)\n",
    "Counter(mcy_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Centroid Undersampling of multiple classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(random_state=1)\n",
    "mcX_resampled, mcy_resampled = cc.fit_resample(mcX_train, mcy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling: combination oversampling and undersampling with SMOTEEN on binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_enn = SMOTEENN(random_state=0)\n",
    "mcX_resampled, mcy_resampled = smote_enn.fit_resample(mcX, mcy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PCA on Binary Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA model intialization 277 columns, reducing complexity\n",
    "pca = PCA(n_components=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA fit and transform for training\n",
    "train_loans_pca = pca.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform testing data using PCA to a DataFrame \n",
    "test_loans_pca = pca.transform(X_test_scaled)\n",
    "X_test_pca_df = pd.DataFrame(data=test_loans_pca)\n",
    "X_test_pca_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PCA data to a DataFrame \n",
    "X_train_pca_df = pd.DataFrame(data=train_loans_pca)\n",
    "X_train_pca_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See explained variance ratio sum - Optimized to explain as much as possible - 225 components is ideal at 95%, no one feature explains \n",
    "# All features are equally important  - 10 features = 9%  - 100 features 50%  -\n",
    "# Mostly linear relationship number of features and explainabilty\n",
    "# PCA DID NOT HELP, WHEN IT REDUCES THE NUMBER OF FEATURES IT ALSO REDUCES EXPLAINABILITY IN A NEARLY LINEAR RELATIONSHIP\n",
    "# THIS ALSO SHOWED UP IN THE ML MODELS, WHERE USING X-SCALED WAS BETTER THAN THE PCA VERSION.\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PCA on Multiple Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA model intialization 277 variables, reducing complexity\n",
    "mc_pca = PCA(n_components=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA fit and transform for training\n",
    "mc_train_loans_pca = mc_pca.fit_transform(mcX_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform testing data using PCA to a DataFrame \n",
    "mc_test_loans_pca = mc_pca.transform(mcX_test_scaled)\n",
    "mc_X_test_pca_df = pd.DataFrame(data=mc_test_loans_pca)\n",
    "mc_X_test_pca_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PCA data to a DataFrame \n",
    "mcX_train_pca_df = pd.DataFrame(data=mc_train_loans_pca)\n",
    "mcX_train_pca_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See explained variance ratio sum - Optimized to explain as much as possible - 225 components is ideal at 95%, no one feature explains \n",
    "# All features are equally important  - 10 features = 9%  - 100 features 50%  -\n",
    "# Mostly linear relationship number of features and explainabilty\n",
    "# PCA DID NOT HELP, WHEN IT REDUCES THE NUMBER OF FEATURES IT ALSO REDUCES EXPLAINABILITY IN A NEARLY LINEAR RELATIONSHIP\n",
    "# THIS ALSO SHOWED UP IN THE ML MODELS, WHERE USING X-SCALED WAS BETTER THAN THE PCA VERSION.\n",
    "sum(mc_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using Multiple Classification buckets as a continuous series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS HERE TOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ????? DO I DO THIS WITHOUT THE SCALED DATA?  Unspecified number of rows, non-scaled data has \n",
    "# mcX = mc_df..values.reshape(-1, 1)  # NEED TO CHANGE SECOND NUMBER TO NUMBER OF COLUMNS, scaled, dummies, pca???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first 5 entries in X\n",
    "mcX_test_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at shape of x, ie number of rows and columns\n",
    "mcX_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at shape of x, ie number of rows and columns\n",
    "mcy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target, the dependent variable, to FUNDING_WEEKS (pre-dummies????  OTHERWISE TOO MANY Ys, but pre-dummies) ????????\n",
    "mcy_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(mcX_train_scaled, mcy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(mcX_test_scaled, mcy_test)   #means square error, make customized accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(mcX_test_scaled)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT OTHER STATISTICS CAN I RUN AND PRINT?????  CORRELATIONS?  PLOT?\n",
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Logistic Regression on SUCCESS and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A synthetic dataset is generated with Scikit-learnâ€™s make_blobs module\n",
    "X, y = make_blobs(centers=2, random_state=42)\n",
    "\n",
    "print(f\"Labels: {y[:10]}\")\n",
    "print(f\"Data: {X[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is visualized\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Logistic Regression Model, Step 1 of 2\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Logistic Regression Model, Step 2 of 2\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "   multi_class='warn', n_jobs=None, penalty='12',\n",
    "   random_state=1, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "   warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression Model  - Using scaled data takes prediction accuracy from 66% to 69%\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Logistic Regression Model\n",
    "y_pred = classifier.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 run predictions\n",
    "pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test[\"SUCCESS\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Confusion Matrix to determine the biggest factors of a fast funding loan\n",
    "matrix = confusion_matrix(y_test,  y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Classification Report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY OUT NEW DATA -- DO WE NEED THIS STEP??? ????????????????????????????????????????\n",
    "# predictions = classifier.predict(new_data)\n",
    "# print(\"Classes are either 0 (Fast) or 1 (Slow)\")\n",
    "# print(f\"The new point was classified as: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SVMs using linear kernel as well as Radical Basis Kernel SVM and Analyze Results.  Tried incorporating PCA but results worsened. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SVC module from Scikit-learn, and instantiate it using linear for the orientation of the hyperplane 68% accuracy\n",
    "model = SVC(kernel='linear')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Radical Basis Kernel SVM *** THIS STEP TAKES 20 MINUTES ***  64.5% accuracy, commented out as Linear SVC above is more accurate\n",
    "\n",
    "# C_2d_range = [1e-2, 1, 1e2]\n",
    "# gamma_2d_range = [1e-1, 1, 1e1]\n",
    "# classifiers = []\n",
    "# for C in C_2d_range:\n",
    "#     for gamma in gamma_2d_range:\n",
    "#         clf = SVC(C=C, gamma=gamma)\n",
    "#         clf.fit(X_train_scaled, y_train)\n",
    "#         classifiers.append((C, gamma, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred,\"Actual\": y_test[\"SUCCESS\"]}).reset_index(drop=True)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess the Accuracy Score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Confusion Matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model on Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS on how to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=78, max_depth=5) # goal is to add more here...\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, \n",
    "# random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None\n",
    "\n",
    "# >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
    "# ...                            n_informative=2, n_redundant=0,\n",
    "# ...                            random_state=0, shuffle=False)\n",
    "# >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# >>> clf.fit(X, y)\n",
    "# RandomForestClassifier(...)\n",
    "# >>> print(clf.predict([[0, 0, 0, 0]]))\n",
    "\n",
    "# see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "y_pred = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Importance of Each Parameter  ****NEED TO DO THIS*****\n",
    "# rf_getparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results  ********ECHO************ HELP ME MAKE ALL THESE THE SAME FOR ALL MODELS ************\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model on Multiple Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS on how to tune, also on inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest may work better looking at buckets of time and what impacts speed of funding a loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "mc_rf_model = RandomForestClassifier(n_estimators=100, random_state=78, max_depth=5) # goal is to add more here...\n",
    "\n",
    "# Fitting the model\n",
    "mc_rf_model = mc_rf_model.fit(mcX_train_scaled, mcy_train)\n",
    "\n",
    "# RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "# min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, \n",
    "# random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None\n",
    "\n",
    "# >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
    "# ...                            n_informative=2, n_redundant=0,\n",
    "# ...                            random_state=0, shuffle=False)\n",
    "# >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# >>> clf.fit(X, y)\n",
    "# RandomForestClassifier(...)\n",
    "# >>> print(clf.predict([[0, 0, 0, 0]]))\n",
    "\n",
    "# see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "Counter(mcy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcy_train['FUNDING_WEEKS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['SUCCESS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "mcy_pred = mc_rf_model.predict(mcX_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at Importance of Each Parameter  ****NEED TO DO THIS*****\n",
    "# rf_getparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score. \n",
    "acc_score = accuracy_score(mcy_test, mcy_pred)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED ACCURACY SCORE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcy_pred[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(mcy_test, mcy_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results  ********ECHO************ HELP ME MAKE ALL THESE THE SAME FOR ALL MODELS ************\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(mcy_test, mcy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Neural nets using mc_df, multiple classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS ABOUND!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy dataset  -- OUT OF WHAT??????????????????  SHOULD I USE MY PREVIOUS GET DUMMIES?????\n",
    "mcX, mcy = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=78)\n",
    "\n",
    "# Creating a DataFrame with the dummy data\n",
    "nn_df = pd.DataFrame(mcX, columns=[\"Feature 1\", \"Feature 2\"])  # HOW MANY COLUMNS?????\n",
    "mm_df[\"Target\"] = y\n",
    "\n",
    "# Plotting the dummy data\n",
    "nn_df.plot.scatter(x=\"Feature 1\", y=\"Feature 2\", c=\"Target\", colormap=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to split dataset    --  COMMENTED OUT BECAUSE ALREADY SPLIT ONCE ABOVE IN DATA PREPROCESSING\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "# ALSO ALREADY SCALED DATA ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model. Sequential groups a linear stack of layers\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our first and only Dense layer, including the input layer  (relu between zero and infinity.  \n",
    "# signmoid activation for S curve b/t 0-1 - could use with bc), or Linear function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"relu\", input_dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(mcX_train_scaled, mcy_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing training history\n",
    "history_df = pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1))\n",
    "\n",
    "# Plot the loss\n",
    "history_df.plot(y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classification of a new set of blob data\n",
    "new_X, new_Y = make_blobs(n_samples=10, centers=2, n_features=2, random_state=78)\n",
    "new_X_scaled = X_scaler.transform(new_X)\n",
    "nn_model.predict_classes(new_X_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
